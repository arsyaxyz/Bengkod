{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bk_Computer_Vision.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arsyaxyz/Bengkod/blob/main/bk_Computer_Visiontugas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnyTxjK_GbOD"
      },
      "source": [
        "# Computer Vision\n",
        "Mari kita lihat skenario di mana kita dapat mengenali item pakaian yang berbeda, dilatih dari kumpulan data yang berisi 10 jenis berbeda."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H41FYgtlHPjW"
      },
      "source": [
        "## Mulai membuat program\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3KzJyjv3rnA",
        "outputId": "1d0f3de2-f52e-476d-d41d-b84a4baa13de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmxkHFpt31bM"
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTdRgExe4TRB",
        "outputId": "1c55d83c-c40c-4d93-e63e-f000d6145520",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPc9d3gJ3jWF",
        "outputId": "2d3a3c47-62f3-4fc1-db26-d079ce6dac56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[0])\n",
        "print(training_labels[0])\n",
        "print(training_images[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
            "    0   1   4   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
            "   54   0   0   0   1   3   4   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
            "  144 123  23   0   0   0   0  12  10   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
            "  107 156 161 109  64  23  77 130  72  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
            "  216 163 127 121 122 146 141  88 172  66]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
            "  223 223 215 213 164 127 123 196 229   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
            "  235 227 224 222 224 221 223 245 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
            "  180 212 210 211 213 223 220 243 202   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
            "  169 227 208 218 224 212 226 197 209  52]\n",
            " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
            "  198 221 215 213 222 220 245 119 167  56]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
            "  232 213 218 223 234 217 217 209  92   0]\n",
            " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
            "  222 221 216 223 229 215 218 255  77   0]\n",
            " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
            "  211 218 224 223 219 215 224 244 159   0]\n",
            " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
            "  224 234 176 188 250 248 233 238 215   0]\n",
            " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
            "  255 255 221 234 221 211 220 232 246   0]\n",
            " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
            "  188 154 191 210 204 209 222 228 225   0]\n",
            " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
            "  168 219 221 215 217 223 223 224 229  29]\n",
            " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
            "  239 223 218 212 209 222 220 221 230  67]\n",
            " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
            "  199 206 186 181 177 172 181 205 206 115]\n",
            " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
            "  195 191 198 192 176 156 167 177 210  92]\n",
            " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
            "  210 210 211 188 188 194 192 216 170   0]\n",
            " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
            "  182 182 181 176 166 168  99  58   0   0]\n",
            " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRH19pWs6ZDn"
      },
      "source": [
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mAyndG3kVlK"
      },
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLMdl9aP8nQ0",
        "outputId": "96eece9d-70dd-4d68-f71f-3a9dd2cd2b1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7866 - loss: 0.6214\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8634 - loss: 0.3750\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8800 - loss: 0.3345\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8867 - loss: 0.3090\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8904 - loss: 0.2945\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c100293d3a0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzlqsEzX9s5P",
        "outputId": "8fa48554-8ac8-43a4-e1d6-0119dca04520",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8731 - loss: 0.3515\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3542094826698303, 0.8718000054359436]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htldZNWcIPSN"
      },
      "source": [
        "# **Latihan Eksplorasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rquQqIx4AaGR"
      },
      "source": [
        "###Latihan 1:\n",
        "Untuk latihan pertama ini jalankan kode di bawah ini: Ini membuat satu set klasifikasi untuk setiap gambar uji, dan kemudian mencetak entri pertama dalam klasifikasi. Outputnya, setelah Anda menjalankannya adalah daftar angka. Menurut Anda mengapa demikian, dan apa yang diwakili oleh angka-angka itu?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyEIki0z_hAD",
        "outputId": "ed28006f-2f8e-4ae9-cea0-f68c7e1dbe1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "[2.62039271e-06 1.61587799e-09 3.19943894e-07 2.51736232e-08\n",
            " 1.01899616e-07 6.44750008e-03 4.12900363e-06 1.94460917e-02\n",
            " 2.73105106e-05 9.74071980e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnBGOrMiA1n5",
        "outputId": "352d01ba-524c-48c5-acff-e7ff7109fc26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(test_labels[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgQSIfDSOWv6"
      },
      "source": [
        "##Latihan 2:\n",
        "Sekarang mari kita lihat lapisan dalam model Anda. Percobaan dengan nilai yang berbeda untuk lapisan padat dengan 512 neuron. Apa hasil berbeda yang Anda dapatkan untuk kerugian, waktu pelatihan, dll? Menurut Anda mengapa demikian?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSZSwV5UObQP",
        "outputId": "76b03597-496d-4957-95ef-89f38274a1bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 14ms/step - loss: 0.5760\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - loss: 0.3641\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 14ms/step - loss: 0.3205\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - loss: 0.2916\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 14ms/step - loss: 0.2755\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3295\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "[1.0446243e-08 1.2007114e-09 1.4712005e-10 3.4820541e-10 6.2880985e-09\n",
            " 8.6102827e-04 3.7754006e-08 2.2050101e-02 1.7979420e-09 9.7708869e-01]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtWxK16hQxLN"
      },
      "source": [
        "##Latihan 3:\n",
        "\n",
        "Apa yang akan terjadi jika Anda menghapus layer Flatten(). Menurut Anda mengapa demikian?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExNxCwhcQ18S",
        "outputId": "1783cf3c-41e4-4b00-ac35-621ea8f04158",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "# This version has the 'flatten' removed. Replace the above with this one to see the error.\n",
        "#model = tf.keras.models.Sequential([tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "#                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6684\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.3993\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.3628\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3318\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3133\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3612\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "[2.9960122e-06 5.5333192e-07 7.3354641e-07 1.8924166e-07 1.0841724e-06\n",
            " 1.1617759e-02 8.1706339e-06 4.0512159e-02 3.6826002e-04 9.4748807e-01]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqoCR-ieSGDg"
      },
      "source": [
        "##Latihan 4:\n",
        "\n",
        "Pertimbangkan lapisan akhir (keluaran). Mengapa ada 10 dari mereka? Apa yang akan terjadi jika Anda memiliki jumlah yang berbeda dari 10? Misalnya, coba latih jaringan dengan 5\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMckVntcSPvo",
        "outputId": "cbd4313f-631a-4e98-cb32-645666445a66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "# Replace the above model definiton with this one to see the network with 5 output layers\n",
        "# And you'll see errors as a result!\n",
        "# model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "#                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "#                                    tf.keras.layers.Dense(5, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6651\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.4024\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.3497\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3284\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.3097\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3651\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "[5.8150586e-06 5.9044498e-07 1.6374133e-06 1.4556603e-07 2.6080854e-05\n",
            " 4.8174798e-03 2.8768488e-06 3.6681868e-02 5.3603770e-05 9.5840985e-01]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0lF5MuvSuZF"
      },
      "source": [
        "##Latihan 5:\n",
        "\n",
        "Pertimbangkan efek dari lapisan tambahan dalam jaringan. Apa yang akan terjadi jika Anda menambahkan lapisan lain antara yang 512 dan lapisan terakhir dengan 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1YPa6UhS8Es",
        "outputId": "522ca864-b771-4dd7-ece2-2be12d89921f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 0.5883\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.3675\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 0.3237\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 0.2928\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.2777\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3490\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "[6.2628130e-10 1.1989053e-09 5.3756830e-09 6.7746382e-09 1.3776644e-09\n",
            " 1.5877925e-04 2.2785194e-08 3.9632045e-04 5.1767102e-09 9.9944484e-01]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bql9fyaNUSFy"
      },
      "source": [
        "#Latihan 6:\n",
        "\n",
        "Pertimbangkan dampak pelatihan untuk epoch yang lebih atau kurang. Menurut Anda mengapa hal itu akan terjadi?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE3esj9BURQe",
        "outputId": "75923fda-0e89-45d6-f0db-b47c2699db26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=30)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[34])\n",
        "print(test_labels[34])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n",
            "Epoch 1/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.6423\n",
            "Epoch 2/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.3831\n",
            "Epoch 3/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 0.3436\n",
            "Epoch 4/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.3118\n",
            "Epoch 5/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.2916\n",
            "Epoch 6/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.2767\n",
            "Epoch 7/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.2658\n",
            "Epoch 8/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.2562\n",
            "Epoch 9/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.2474\n",
            "Epoch 10/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.2414\n",
            "Epoch 11/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.2349\n",
            "Epoch 12/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.2273\n",
            "Epoch 13/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.2154\n",
            "Epoch 14/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.2094\n",
            "Epoch 15/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.2024\n",
            "Epoch 16/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.1964\n",
            "Epoch 17/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.1937\n",
            "Epoch 18/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.1905\n",
            "Epoch 19/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.1806\n",
            "Epoch 20/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.1802\n",
            "Epoch 21/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.1752\n",
            "Epoch 22/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.1678\n",
            "Epoch 23/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.1672\n",
            "Epoch 24/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.1606\n",
            "Epoch 25/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.1602\n",
            "Epoch 26/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.1567\n",
            "Epoch 27/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.1502\n",
            "Epoch 28/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 0.1515\n",
            "Epoch 29/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.1482\n",
            "Epoch 30/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.1449\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4065\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "[4.8496371e-21 2.9621468e-23 4.0419268e-21 7.9611619e-27 2.2376749e-18\n",
            " 1.6865039e-18 1.8579745e-24 3.4621582e-33 9.9999994e-01 1.2483987e-32]\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS3vVkOgCDGZ"
      },
      "source": [
        "#Latihan 7:\n",
        "\n",
        "Sebelum Anda melatih, Anda menormalkan data, mulai dari nilai 0-255 ke nilai 0-1. Apa dampak dari penghapusan itu? Berikut kode lengkap untuk mencobanya. Jika anda berfikir bahwa Anda mendapatkan hasil yang berbeda? Mengapa Anda berfikir demikian?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDqNAqrpCNg0",
        "outputId": "92df1e67-f3bf-4a51-9065-2aa62eea2d49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "# To experiment with removing normalization, comment out the following 2 lines\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - loss: 0.5908\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - loss: 0.3679\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - loss: 0.3268\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.2966\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - loss: 0.2825\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3376\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "[3.1020587e-08 9.7097497e-10 9.8761772e-09 1.2450515e-11 1.5432227e-09\n",
            " 3.9689166e-05 5.1610357e-08 2.9507722e-03 1.9412512e-09 9.9700940e-01]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7W2PT66ZBHQ"
      },
      "source": [
        "#Exercise 8:\n",
        "\n",
        "Sebelumnya ketika Anda berlatih untuk ekstra epoch, Anda memiliki masalah di mana tingkat kegagalan Anda mungkin berubah. Mungkin perlu sedikit waktu bagi Anda untuk menunggu pelatihan untuk melakukan itu, dan Anda mungkin berpikir 'bukankah lebih baik jika saya bisa menghentikan pelatihan ketika saya mencapai nilai yang diinginkan?' -- yaitu akurasi 95% mungkin cukup untuk Anda, dan jika Anda mencapainya setelah 3 epoch, mengapa menunggu hingga epoch menyelesaikan lebih banyak....Jadi bagaimana Anda memperbaikinya? Seperti program lain... Anda dapat memanfaatkan callbacks!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkaEHHgqZbYv",
        "outputId": "a67ca4ad-d5c5-45f7-8970-3f0551e31435",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.9):\n",
        "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.7961 - loss: 0.5882\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8706 - loss: 0.3590\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.8805 - loss: 0.3246\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8923 - loss: 0.2943\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.8961 - loss: 0.2788\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c0fc06a91f0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gSikUA_NAipx"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}